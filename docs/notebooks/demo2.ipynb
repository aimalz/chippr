{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHIPPR\n",
    "\n",
    "This notebook demonstrates the use of the Cosmological Hierarchical Inference with Probabilistic Photometric Redshifts (CHIPPR) package to estimate population distributions based on a catalog of probability distributions.\n",
    "\n",
    "The package supports two primary objectives: simulation of catalogs and inference of posterior distributions over parameters defining population distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import timeit\n",
    "import cProfile, pstats, StringIO\n",
    "import os\n",
    "\n",
    "import chippr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "help(chippr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulation\n",
    "\n",
    "Many of `chippr`'s modules are used to produce mock catalogs of individual posterior probability distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a catalog, we must first define a true redshift distribution function.  It may be a Gaussian distribution of the `gauss` class, a Gaussian mixture distribution of the `gmix` class, or a binned discrete distribution of the `discrete` class.  In this case, we will consider a mixture of three Gaussian distributions to represent the true redshift distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "true_amps = np.array([0.20, 0.35, 0.55])\n",
    "true_means = np.array([0.5, 0.2, 0.75])\n",
    "true_sigmas = np.array([0.4, 0.2, 0.1])\n",
    "\n",
    "true_nz = chippr.gmix(true_amps, true_means, true_sigmas, limits=(0., 1.))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we sample true redshifts from that distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N =10**4 #2**16\n",
    "\n",
    "true_zs = true_nz.sample(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`chippr` supports the use of a parameter file to specify various options for the catalog simulator and inference module to turn on and off."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_loc = 'params.txt'\n",
    "params = chippr.utils.ingest(param_loc)\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make a catalog, we must specify an interim prior redshift distribution $n^{*}(z)$, regardless of what quantity we wish to infer using the catalog.  So far, only discrete distributions are supported, but this will soon be changed.  The simplest discrete distribution is uniform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "bin_ends = np.array([0., 1.])\n",
    "weights = np.array([1.])\n",
    "\n",
    "int_prior = chippr.discrete(bin_ends, weights)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to make a catalog.  To do this we instantiate a `catalog` object and then create a catalog of indiviual posterior distributions based on the true redshifts and the interim prior.  By default, the catalog generator will make some informative plots along the way.  The included plots are a histogram of the true redshifts and a scatterplot of the true redshifts and the centers of the individual Gaussian posteriors.  Support for other posterior forms will be added soon.  Additionally, the catalog is expressed as normalized binned histogram heights.  Support for other parametrizations of the individual posteriors may be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "results_loc = os.path.join(os.path.join(os.path.join(os.path.join('..', '..'), 'research'), 'results'), 'demo')\n",
    "\n",
    "posteriors = chippr.catalog(params=param_loc, loc=results_loc)\n",
    "output = posteriors.create(true_zs, int_prior)\n",
    "\n",
    "data = np.exp(output['log_interim_posteriors'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also plot a histogram of the centers of the individual Gaussian posteriors, a binned version of the true redshift distribution, and the $n(z)$ resulting from stacking the individual posteriors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "plt.hist(posteriors.obs_samps, bins=100, normed=True, color=\"k\")\n",
    "plt.plot(posteriors.z_coarse, true_nz.evaluate(posteriors.z_coarse), \"r-\")\n",
    "plt.plot(posteriors.z_coarse, np.sum(data, axis=0) / N, \"go\")\n",
    "plt.xlabel(\"z\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is also informative to see what a few individual likelihoods and binned posteriors look like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n, z in enumerate(data[:10]):\n",
    "    plt.plot(posteriors.z_coarse, data[n], 'ko')\n",
    "    plt.plot(posteriors.z_fine, posteriors.obs_lfs[n], 'k-')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We finish by saving the data as a plaintext file.  Support for more file formats will be added soon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "saved_location = 'data'\n",
    "saved_type = '.txt'\n",
    "posteriors.write(loc=saved_location, style=saved_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "`chippr` currently contains one inference module to probe the posterior distribution of parameters defining the redshift distribution function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To perform inference, we must create a catalog object.  This may be done by making a new catalog as is done above or by reading in an existing catalog file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "param_loc = 'params.txt'\n",
    "results_loc = os.path.join(os.path.join(os.path.join(os.path.join('..', '..'), 'research'), 'results'), 'demo')\n",
    "simulated_posteriors = chippr.catalog(params=param_loc, loc=results_loc)\n",
    "\n",
    "saved_location = 'data'\n",
    "saved_type = '.txt'\n",
    "data = simulated_posteriors.read(loc=saved_location, style=saved_type)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The catalog file contains three components: the `bin_ends`, the `log_interim_prior`, and the `log_interim_posteriors`.  The bin endpoints can be processed to enable their use in constructing a prior distribution over the parameters determining the redshift distribution function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "zs = data['bin_ends']\n",
    "nz_intp = np.exp(data['log_interim_prior'])\n",
    "z_posts = np.exp(data['log_interim_posteriors'])\n",
    "\n",
    "z_difs = zs[1:]-zs[:-1]\n",
    "z_mids = (zs[1:]+zs[:-1])/2.\n",
    "n_bins = len(z_mids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The prior distribution must be a `mvn` object, defined by a mean vector and covariance matrix over the parameters defining the redshift distribution.  In this case, it is intuitive to use the definition of the binning strategy to create the prior distribution since the parameters are normalized histogram bin heights, the same parametrization used for the catalog entries themselves."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# prior_sigma = 0.16\n",
    "# prior_var = np.eye(n_bins)\n",
    "# for b in range(n_bins):\n",
    "#     prior_var[b] = 1. * np.exp(-0.5 * (z_mids[b] - z_mids) ** 2 / prior_sigma ** 2)\n",
    "# l = 1.e-4\n",
    "# prior_var = prior_var+l*np.identity(n_bins)\n",
    "\n",
    "prior_var = np.eye(n_bins)\n",
    "for k in range(n_bins):\n",
    "    prior_var[k] = 1. * np.exp(-0.5 * (z_mids[k] - z_mids) ** 2 / 0.05 ** 2)\n",
    "\n",
    "prior_mean = nz_intp\n",
    "prior = chippr.mvn(prior_mean, prior_var)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a `log_z_dens` object from the dictionary of catalog parameters and the prior distribution.  We include the optional specification of the true distribution, since it is available in this case.  We also include a parameter file that may contain default constants for the inference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz = chippr.log_z_dens(data, prior, truth=true_nz, vb=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform calculations of a few of the simplest estimators of the redshift distribution function $\\hat{n}(z)$.  The stacked estimator is defined as $\\hat{n}(z)=\\frac{1}{N}\\sum p(z|\\vec{d},n^{*}(z))$.  The marginalized maximum a posteriori estimator is defined as $\\hat{n}(z)=\\hat{n}(\\{argmax[p(z|\\vec{d},n^{*}(z))]\\})$.  The marginalized expected value estimator is defined as $\\hat{n}(z)=\\hat{n}(\\{E[p(z|\\vec{d},n^{*}(z))]\\})$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz_stacked = nz.calculate_stacked()\n",
    "nz_mmap = nz.calculate_mmap()\n",
    "nz_mexp = nz.calculate_mexp()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `log_z_dens` object enables easy comparison between estimators using the Kullback-Leibler Divergences (when the true distribution is available) and root-mean-square differences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may next calculate the marginalized maximum likelihood estimator (which actually returns the parameters maximizing the posterior probability)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz_mmle = nz.calculate_mmle(nz_stacked)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we are very ambitious, we can run an MCMC sampler (currently use of `emcee` is supported, but other samplers may be added in the future) to probe the posterior distribution of the parameter values.  To do this, we initialize the sampler with samples from the prior distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "n_ivals = 2*n_bins\n",
    "initial_values = prior.sample(n_ivals)\n",
    "\n",
    "nz_samps = nz.calculate_samples(initial_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz_stats = nz.compare()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `log_z_dens` object stores the estimators that have been calculated as well as all metadata associated with the posterior samples.  The storage of the metadata and samples will soon be eliminated in favor of saved files, as that information may necessitate a great deal of memory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz.info['estimators'].keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the results of all previously calculated estimators (and the true redshift density function, if it was provided) may be plotted automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "nz.plot_estimators()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `log_z_dens` object supports writing the information associated with the estimators to a file in the `pickle` format, though other formats may be added in the future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz.write('nz.p')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we demonstrate that the written estimators may be loaded from files as well for future use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nz.info = nz.read('nz.p')\n",
    "print(nz)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
